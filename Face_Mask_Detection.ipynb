{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbafathi/006-Face_Recognition_Example/blob/main/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zytgr-sJ9Tz7"
      },
      "outputs": [],
      "source": [
        "!pip install pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtwJc_9Z9xT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3"
      ],
      "metadata": {
        "id": "Sl0gfmsE0VhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58N1yYpC9xM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SR1Fyyq59a2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aagKrXAd9mlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEIRU3FWzfYB"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engine = pyttsx3.init('dummy')\n",
        "voices = engine.getProperty('voices')\n",
        "engine.setProperty('voices',voices[1].id)\n",
        "print(voices[0].id)\n",
        "speed = 1500\n",
        "engine.setProperty('rate',speed)"
      ],
      "metadata": {
        "id": "j_4ZmYtr93bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(audio):\n",
        "  engine.say(audio)\n",
        "  engine.say(audio)\n",
        "  engine.runAndWait()\n",
        "speak('welcome to face mask detection')"
      ],
      "metadata": {
        "id": "hw29m0Wd-eaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81eH_VUrEYGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
        "\t# grab the dimensions of the frame and then construct a blob\n",
        "\t# from it\n",
        "\t(h, w) = frame.shape[:2]\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (250, 250),\n",
        "\t\t(180.0, 125.0, 130.0))\n",
        "\n",
        "\t# pass the blob through the network and obtain the face detections\n",
        "\tfaceNet.setInput(blob)\n",
        "\tdetections = faceNet.forward()\n",
        "\tprint(detections.shape)\n",
        "\n",
        "\t# initialize our list of faces, their corresponding locations,\n",
        "\t# and the list of predictions from our face mask network\n",
        "\tfaces = []\n",
        "\tlocs = []\n",
        "\tpreds = []\n",
        "\n",
        "\t# loop over the detections\n",
        "\tfor i in range(0, detections.shape[2]):\n",
        "\t\t# extract the confidence (i.e., probability) associated with\n",
        "\t\t# the detection\n",
        "\t\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\t\t# filter out weak detections by ensuring the confidence is\n",
        "\t\t# greater than the minimum confidence\n",
        "\t\tif confidence > 0.5:\n",
        "\t\t\t# compute the (x, y)-coordinates of the bounding box for\n",
        "\t\t\t# the object\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t# ensure the bounding boxes fall within the dimensions of\n",
        "\t\t\t# the frame\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\n",
        "\t\t\t# ordering, resize it to 224x224, and preprocess it\n",
        "\t\t\tface = frame[startY:endY, startX:endX]\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\t\tface = cv2.resize(face, (250, 250))\n",
        "\t\t\tface = img_to_array(face)\n",
        "\t\t\tface = preprocess_input(face)\n",
        "\n",
        "\t\t\t# add the face and bounding boxes to their respective\n",
        "\t\t\t# lists\n",
        "\t\t\tfaces.append(face)\n",
        "\t\t\tlocs.append((startX, startY, endX, endY))\n",
        "\n",
        "\t# only make a predictions if at least one face was detected\n",
        "\tif len(faces) > 0:\n",
        "\t\t# for faster inference we'll make batch predictions on *all*\n",
        "\t\t# faces at the same time rather than one-by-one predictions\n",
        "\t\t# in the above `for` loop\n",
        "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
        "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
        "\n",
        "\t# return a 2-tuple of the face locations and their corresponding\n",
        "\t# locations\n",
        "\treturn (locs, preds)\n",
        "\n",
        "# load our serialized face detector model from disk\n",
        "prototxtPath = r\"/content/deploy.prototxt\"\n",
        "weightsPath = r\"/content/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "\n",
        "# load the face mask detector model from disk\n",
        "maskNet = load_model(\"/content/TrainedModel.model\")\n",
        "\n",
        "# initialize the video stream\n",
        "print(\"starting video stream...\")\n",
        "speak(\"Starting video stream...\")\n",
        "vs = VideoStream(src=0).start()\n",
        "\n",
        "\n",
        "\t\n",
        "\n",
        "\t\t# "
      ],
      "metadata": {
        "id": "_ST4bLt5-x9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "8VF9SZYeHbSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "X19hob3CHcMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detections():\n",
        "  while True:\n",
        "    frame = cv2.imread('/content/th.jpg')\n",
        "    frame = imutils.resize(frame,width = 1000)\n",
        "    mask,withoutmask = detect_and_predict_mask(frame,faceNet,maskNet)\n",
        "    startX,startY = detect_and_predict_mask(frame,faceNet,maskNet)\n",
        "    endX,endY = detect_and_predict_mask(frame,faceNet,maskNet)\n",
        "\n",
        "    label = \"Mask\" \n",
        "    if mask > withoutmask:\n",
        "      print('MASKED')\n",
        "    else:\n",
        "      print('UNMASKED')\n",
        "    color = (0,255,0)\n",
        "    if label == 'mask':\n",
        "      print('NONE')\n",
        "    else:\n",
        "      print(color)\n",
        "    label = \"{}:{:.2f}%\".format(label,max(mask,withoutmask)*100)\n",
        "    cv2.openText(frame,label,startX,startY - 10,cv2.FONT_HERSHEY_COMPLEX,0.45,color,2)\n",
        "    cv2.rectangle(frame,startX,startY,endX,endY,color,2)\n",
        "    \n",
        "    cv2.imshow(\"frame\",frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord(\"b\"):\n",
        "      break\n",
        "\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\t\t# include the probability in the label\n",
        "\t\t\n"
      ],
      "metadata": {
        "id": "7pA6clf-EXjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}